{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd97111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Set LangSmith Environment Variables\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c0a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chat model!\n",
      "Chat model initialization over!\n"
     ]
    }
   ],
   "source": [
    "# Set up google llm model for RAG usage\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "print(\"Initializing chat model!\")\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "print(\"Chat model initialization over!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23c2913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedder model!\n",
      "Embedder model initialized!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing embedder model!\")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "print(\"Embedder model initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35bbca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize vector store!\n",
      "Vector store initialized!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize vector store!\")\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "print(\"Vector store initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b29c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading documents for RAG use\n",
    "\n",
    "# get beautiful soup\n",
    "import bs4\n",
    "# get Document Loaders\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "desired_webpage_link = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "# the original tutorial only wanted us to keep html tags that\n",
    "# contain any of the class names listed in the tuple assigned to the \n",
    "# class_ keyword, in the below variable. We discard all other html tags.\n",
    "bs4_filtered = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "webpage_loader = WebBaseLoader(\n",
    "  web_paths=(desired_webpage_link,),\n",
    "  bs_kwargs={\"parse_only\": bs4_filtered}\n",
    ")\n",
    "\n",
    "documents = webpage_loader.load()\n",
    "#for key in documents[0]:\n",
    "  #print(f\"New key: {key}\")\n",
    "#print(f\"how many characters are in our page: {len(documents[0].page_content)}\")\n",
    "#print(f\"The first two thousand characters of the document: {documents[0].page_content[:2000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d03c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# create a text splitter instance\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=200,\n",
    "  add_start_index=True,\n",
    ")\n",
    "\n",
    "# obtain splitted text. our document is now a bunch of document shards.\n",
    "splitted_text = recursive_text_splitter.split_documents(documents)\n",
    "#print(f\"The splits we got back:\\n\\n{splitted_text[4].page_content}\")\n",
    "#print(f\"Number of splits:{len(splitted_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49a315",
   "metadata": {},
   "source": [
    "# We've loaded in our document. \n",
    "Split it up into text chunks, to allow our model to access bits of the data that fit into the LLM context window.\n",
    "\n",
    "Now, it's time to put these chunks into a storage format the LLM can access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70699a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vector store was previously initialized with our defined embeddings\n",
    "# in one command sequence, we tell the vector store to embed each of our document chunks.\n",
    "# we then store the embedded versions of these chunks into our vector store, for \n",
    "# later retrieval\n",
    "vector_store__document_embedded_vectors = vector_store.add_documents(splitted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3de96322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store shape: ['9e7d4870-5720-4526-8f77-e36463bc63e2', 'a641e2ab-fb0d-4f70-b70c-23e6806197cf', '4bec83f9-0f77-4b2c-b65c-e8204629e5ef', 'cdfecf70-e108-4e00-847a-13555c6eac38', '5fa4ec99-0bdc-45fa-b64a-60c796255246', '88d537ed-3ee8-4cda-a1ee-da2a7652c6ab', '3d74db9d-dba9-4c7c-8bb2-dd8ad8915b79', '267b6707-11f3-4b4c-bcd4-da91d5764c00', '13528c3f-e17a-4582-bdab-d8ae4c4926f2', '6cb5d11a-550a-409b-baad-664faf669cda', 'e04f327b-b3ca-4511-bac2-9b5ce05db924', '389bba3a-0a1d-4456-8b68-7176e10d80e1', '82be8ba8-50b6-4838-8bfd-f556c37acacb', 'ac133bdc-072c-4489-bc4b-1693938ae216', '94ee69d2-3acf-44ee-97d6-4e1f4cc6e17b', '5fa6a103-8913-43be-9076-d0808a74f1e3', 'dc9af879-20d1-4335-87e7-ceafe0f6ca13', 'd7a4a3c5-1f18-45c8-b43c-bbb34ad634e5', 'ba0adb1e-7bfd-46f2-926b-78a1fdd34454', 'c6330ffa-4f71-494d-9e44-ed1d037f77f7', '6d431b74-77f0-453f-a43c-5f489eeb9134', '98599d29-aee2-45ed-9e91-196d2dc9f43b', 'a0d640f2-9073-4423-a9e0-482604af3ac8', '290eae8d-c363-4e77-828f-77eb569339b5', '2fa6b39a-2289-439a-8ab9-2ec94a7be586', '2add5583-094f-432d-8abd-25150ed8e836', '2c037269-d592-4360-a4e3-3c22f239d09a', 'd216cc88-bcfe-4815-886c-4e5b670fb27c', 'd8c091bd-632c-45a0-a741-1f7e63328a6c', 'cbdaa0b5-557f-425b-8eea-6428cfc8f2a6', 'adcbaa74-9254-4a31-a38f-659c92a497ce', '6437b4d7-f6ce-42d6-b2d7-d721fcf52753', '72fef90a-1049-44d8-b801-0d675c434c4e', 'f1364e47-6aab-4b25-bf99-d42c62166be8', '68b02670-acc8-41a7-a5eb-7fed3f6d31c5', '6ba6d675-f0e5-41e7-8292-a4fa964753fc', 'ecf289e5-81c5-4be0-8f26-b21a84db5a69', '0012defb-9c5f-413d-a095-be4648504627', 'e548adab-3f19-479f-b423-08769d749651', 'dabad9a2-5d50-45b0-bb38-05398baefa3d', '94c3d5e5-ce9d-4e0e-a5b5-3aae0c266d71', 'aa41d5a3-7961-457c-bf74-7b34486b2842', 'd7bb7203-0aac-4186-bad8-c1e53fd8a5d0', '36121570-33b9-4de2-ae3b-ac8761a74f55', '08e159f9-3cc5-4d24-a6de-87238f1f3843', '2fa905b9-96b7-47c6-809a-d97733db9a52', 'd5b10368-1120-48b7-90b5-1077bf867d34', '23585d58-d453-4d56-8ca6-30bc5f190aca', 'f49cc2aa-e7ad-4b98-a6d9-9f38f9151e2f', '44fdc269-55ac-4fe6-b350-a186398efcc1', 'e278baf4-2bf1-4cc5-9980-3ccf78c16f51', '01a52457-18b3-4840-81f1-84643367fd8d', 'eb7c85c2-0187-4234-a226-1db5b20af78b', '1ddad44d-3151-4898-b1f4-185a95127c5f', '0745669a-fd57-44fb-bf8c-1f397bbe0efe', '6e15accc-f7ad-4cee-9e3f-d9f05f794f1c', '213c806d-cf87-486b-956d-2c53f50fd677', 'db1cad17-9f14-4466-ba35-f1b36c6d68eb', '062f315b-9eb8-452e-ba5d-ce4a55a21164', 'a52d5974-5fbb-4cf5-a1f3-9576aca1a9b8', '513a78e0-018b-43a5-b49f-e2fc31654b41', 'ae1e2a82-23f8-42b0-86b9-45ef7c860f06', '86f16023-c0c2-4829-93a0-0129d2179a28', '71c6a98e-e9fe-46a1-be71-58d9b21adc6d', '75a3935b-ee84-42f4-8acf-c701043f72c1', '33a83082-e5ce-46c8-a1f1-4ecca8c44a0d']\n"
     ]
    }
   ],
   "source": [
    "print(f\"vector store shape: {vector_store__document_embedded_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7784050",
   "metadata": {},
   "source": [
    "# We now should be able to answer User Queries\n",
    "By accessing our vector store and returning the relevant chunks of text, from Lillian's blog post, that answers the user's questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-agent-musings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
